# Proyecto de Talento Tech

## Proposito del proyecto
Este proyecto tiene como objetivo automatizar pruebas de UI y de API para el sitio **SauceDemo**, aplicando practicas como Page Object Model, manejo de datos externos, generacion de reportes HTML, logging y captura automatica de pantalla.

## Tecnologias utilizadas
- Python 3.x
- Pytest
- Selenium WebDriver
- Logging
- Faker
- CSV / JSON
- Request

## ğŸ“‘ Estructura del proyecto

- **assets/** â†’ Recursos grÃ¡ficos y estÃ¡ticos utilizados en reportes.
- **datos/** â†’ Archivos de entrada y datos de prueba.
- **logs/** â†’ Registros de ejecuciÃ³n y trazabilidad de procesos.
- **pages/** â†’ PÃ¡ginas o plantillas relacionadas con la automatizaciÃ³n.
- **reports/** â†’ Reportes generados automÃ¡ticamente.
- **tests/** â†’ Casos de prueba automatizados.
- **utils/** â†’ Funciones auxiliares y herramientas de soporte.
- **conftest.py** â†’ ConfiguraciÃ³n de Pytest.
- **run_tests.py** â†’ Script principal para ejecutar pruebas.
- **report.html** â†’ Ejemplo de reporte generado.
- **readme.md** â†’ Documento de referencia del proyecto.

## Reportes y Logs

El proyecto genera tres tipos principales de resultados durante la ejecucion de las prubas: **reporte HTML**, **capturas de pantalla**, **archivo de log**

### Reporte HTML
Se genera un reporte HTML detallado con el nombre de ```reporte.hmtl``` en la **carpeta raiz** del proyecto

### Logs de ejecuciÃ³n
Tambien se genera un log con informacion detallada de toda la ejecuciÃ³n de las pruebas en la siguiente ubicacion: ```logs/suite.log```

### Capturas de pantalla

Se realizan capturas de pantalla por cada test que haya fallado y se encuentran en la siguiente ubicacion: ```reports/screens/```

## Ejuctar todas las pruebas
Para iniciar la ejecucion de las pruebas debes ejecutar la siguiente linea:

```bash
python -m run_test.py
```

## Â¿Como interpretar los reportes?
- Al ejecutar `run_test.py`, se genera un archivo HTML en la carpeta raiz.
- El reporte incluye:
    - Lista completa de test ejecutados
    - El estado de cada prueba
    - La duracion de cada test
    - Las capturas de pantalla para pruebas fallidas

## Pruebas incluidas
- Login exitoso y fallido
- Login exitoso y fallido usando faker
- Comportamiento de la pagina de inventario
- Comportamiento de la pagina del carrito
- API (Reqres): GET users, POST create user, DELETE user, validaciones de codigos HTTP, validaciones de estructura JSON

## Manejo de datos de prueba
- En la carpeta `datos` se incluyen archivos como:
    - `data_login.csv` -> datos de usuarios validos o invalidos
    - `productos.json` -> datos de productos para validacion

## Autor
SggSeguridad  Alias: Rockito
- Referente institucional y especialista tÃ©cnico en seguridad informÃ¡tica, automatizaciÃ³n y monitoreo IP.
- Este proyecto forma parte de la lÃ­nea de trabajo orientada a la mejora continua, trazabilidad y documentaciÃ³n tÃ©cnica.

### Conclusion
Este proyecto ofrece una estructura organizada y escalable para automatizar pruebas de API utilizando Python y Pytest. Incluye un flujo simple de ejeucion mediante `run_test.py`, generacion automatica de reporte HTML facilitando el analisis de las pruebas.

La arquitectura del proyecto esta pensada para agregar nuevos casos de prueba y configuraciones sin modificar el nucleo del proyecto, manteniendo buenas practicas y permitiendo su escalabilidad en el tiempo.


# ğŸš€ Proyecto de Talento Tech â€“ AutomatizaciÃ³n de Pruebas

## ğŸ¯ PropÃ³sito del Proyecto
El objetivo de este proyecto es automatizar pruebas **UI** y **API** sobre el sitio **SauceDemo**, aplicando buenas prÃ¡cticas de automatizaciÃ³n como **Page Object Model (POM)**, manejo de datos externos, generaciÃ³n automÃ¡tica de reportes HTML, logging estructurado y capturas de pantalla ante fallos.

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas
- **Python 3.x**
- **Pytest**
- **Selenium WebDriver**
- **Logging**
- **Faker**
- **CSV / JSON**
- **Requests**

---

## ğŸ“‚ Estructura del Proyecto

assets/ â†’ Recursos grÃ¡ficos usados en reportes
datos/ â†’ Datos de entrada para pruebas (CSV/JSON)
logs/ â†’ Registros de ejecuciÃ³n
pages/ â†’ ImplementaciÃ³n del Page Object Model
reports/ â†’ Reportes generados automÃ¡ticamente
tests/ â†’ Casos de prueba UI y API
utils/ â†’ Funciones auxiliares
conftest.py â†’ ConfiguraciÃ³n de Pytest
run_tests.pyâ†’ Script principal para ejecutar pruebas
report.html â†’ Ejemplo de reporte generado
readme.md â†’ DocumentaciÃ³n del proyecto


---

## ğŸ“ Reportes y Logs

### ğŸ“„ Reporte HTML
- Se genera automÃ¡ticamente con el nombre **`reporte.html`** en la **carpeta raÃ­z**.
- Incluye:
  - Estado de cada prueba  
  - Tiempos de ejecuciÃ³n  
  - Capturas de pantalla asociadas a errores  

### ğŸ§¾ Logs de EjecuciÃ³n
- Archivo generado: **`logs/suite.log`**
- Contiene:
  - Flujo de ejecuciÃ³n  
  - Errores  
  - InformaciÃ³n contextual para depuraciÃ³n  

### ğŸ“¸ Capturas de Pantalla
- Se guardan Ãºnicamente cuando un test falla  
- UbicaciÃ³n: **`reports/screens/`**

---

## â–¶ï¸ EjecuciÃ³n de las Pruebas
Para ejecutar la suite completa:

```bash
python -m run_test.py
```

ğŸ§ª Pruebas Incluidas

ğŸ” UI â€“ Login

Login exitoso

Login fallido

Login utilizando datos generados con Faker

ğŸ›’ UI â€“ Funcionalidades Principales

ValidaciÃ³n de la pÃ¡gina de inventario

Pruebas sobre el carrito de compras

ğŸŒ API â€“ Reqres

GET users

POST create user

DELETE user

ValidaciÃ³n de cÃ³digos HTTP

ValidaciÃ³n de estructura JSON

ğŸ“Š Manejo de Datos de Prueba

Ubicados dentro de datos/:

data_login.csv â†’ Usuarios vÃ¡lidos e invÃ¡lidos

productos.json â†’ InformaciÃ³n para validaciones de productos

ğŸ‘¤ Autor

Erik Tomas Verna
Analista en Sistemas
Enfoque en automatizaciÃ³n, calidad de software y documentaciÃ³n tÃ©cnica.

âœ”ï¸ ConclusiÃ³n

Este proyecto proporciona una arquitectura clara, ordenada y fÃ¡cilmente escalable para automatizar pruebas con Python y Pytest. Su diseÃ±o permite agregar nuevos casos y configuraciones sin modificar el nÃºcleo del sistema, asegurando mantenibilidad, trazabilidad y eficiencia a largo plazo.